# Azure Data Engineering Project â€“ End-to-End Pipeline (Bronze â†’ Silver â†’ Gold)

This project demonstrates a complete data engineering pipeline using Microsoft Azure services. It shows how raw data is fetched from the internet (via HTTP link), processed through different layers (bronze, silver, gold), and made ready for reporting in Power BI.

## ğŸ“Œ Project Overview

This pipeline follows the **modern data lake architecture** pattern:

1. **Bronze Layer** â€“ Stores raw data from the source (HTTP link)
2. **Silver Layer** â€“ Stores cleaned and transformed data (using Databricks + PySpark)
3. **Gold Layer** â€“ Stores final business-level aggregated data (using Azure Synapse)

This data is finally connected to **Power BI** for analysis and dashboards.

## ğŸ”„ Project Workflow

ğŸ“¥ HTTP Data Source 
      â†“
ğŸ“¦ Azure Data Factory (ADF)
      â†“
ğŸŸ« Bronze Layer (Raw Data in Data Lake)
      â†“
ğŸ§ª Azure Databricks (PySpark Transformation)
      â†“
â¬œ Silver Layer (Clean Data in Data Lake)
      â†“
ğŸ› Azure Synapse Analytics (Final Transformations / Joins)
      â†“
ğŸ“Š Power BI (Visualization and Reporting)


## ğŸ› ï¸ Tools & Technologies Used

- **Azure Data Factory** â€“ To fetch and copy data using HTTP Linked Service and store in Bronze layer
- **Azure Data Lake Storage Gen2** â€“ Used as the storage layer (Bronze, Silver)
- **Azure Databricks** â€“ For data transformation and cleaning using PySpark
- **Azure Synapse Analytics** â€“ For loading data into structured warehouse tables (Gold layer)
- **Power BI** â€“ For visualizing final datasets and building reports
- **PySpark / Python** â€“ Used inside Databricks for data transformation
  
## âœ… Key Learnings

- End-to-end ETL/ELT data pipeline in Azure
- Practical use of Bronze, Silver, and Gold architecture
- Hands-on with real Azure tools used in industry
- Ready-to-show project for portfolio or job interviews
